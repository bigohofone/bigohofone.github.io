[
  {
    "title": "Samsung Fire & Marine Insurance Chatbot",
    "client": "GenON",
    "start": [null, 12, 2024],
    "end": [null, 2, 2025],
    "details": {
      "Description": "사고의 보험 약관상 면/부책 여부를 판단하는 ToD 챗봇 개발을 수행하였습니다. 복잡한 보험 서류 참고, 다단계/다양한 사고 패턴을 요구하는 보험 태스크를 범용적인 하나의 CoT 계열 프롬프트로 해결하는 것이 어려운 문제가 있었습니다. 따라서, 실무와 협업하여 태스크를 분류한 후 사고 로직을 디자인, 파이프라인화하였고 실무에서 요구하는 정성적 평가 기준을 만족할 수 있었습니다. 또한 FastAPI 기반의 WebSocket 실시간 대화형 엔드 포인트 개발, 비동기 처리, Singleton 패턴 적용, Docker를 활용한 배포까지 전체 엔지니어링을 경험하고, 인퍼런스 시간을 기존 12초에서 6초로 절반가량 단축했습니다."
    }
  },
  {
    "title": "Product QA Chatbot",
    "client": "LS Electric",
    "start": [null, 4, 2024],
    "end": [null, 8, 2024],
    "details": {
      "Description": "제품 문의에 대한 QA를 수행하는 RAG 챗봇 개발을 수행하였습니다. 제품에 따라 봐야 하는 문서가 정해져있지만, 모든 문서의 내용이 대동소이하여 의미를 기반으로 검색하는 기존 검색 시스템으로는 개선하기 어렵다는 문제가 있었습니다. 쿼리에 따라 제품의 종류를 추출하는 모델을 개발하고, 이를 검색 필터링에 적용하여 현업에서 측정한 QA 정확도를 기존 50%에서 85%로 개선하였습니다. 또한 추출되지 않을 경우 대답하지 않도록 하여 답변 안정성을 크게 개선하였습니다. 또한 이를 LangChain을 사용하여 Flask로 실제 고객에게 배포하고, 피드백을 받아 개선하였습니다."
    }
  },
  {
    "title": "Outfit Transformer Re-implementation",
    "client": "Personal Project",
    "start": [null, 12, 2023],
    "end": [null, 2, 2024],
    "details": {
      "Situation": "In the fashion AI domain, there was a lack of high-performing open-source outfit recommendation systems as of 2023. Existing models struggled with generalization under limited data and failed to separate the learning of item representations from compatibility prediction. Additionally, most state-of-the-art (SoTA) approaches prioritized accuracy over training efficiency and real-world applicability.",
      "Task": [
        "Develop a scalable and high-performance outfit recommendation model that performs well even with limited data.",
        "Address the limitations of jointly learning item representation and recommendation compatibility.",
        "Optimize the model for practical use cases by reducing training and inference time without sacrificing performance."
      ],
      "Action": [
        "Modularized Architecture: Refactored the original Outfit Transformer to decouple visual representation learning from compatibility modeling.",
        "Representation Learning with CLIP: Replaced the visual encoder with CLIP, leveraging its strong generalization capabilities for fashion image embeddings.",
        "Efficiency Optimization: Pre-computed item embeddings before training, significantly reducing runtime by eliminating redundant computation during each epoch.",
        "Open-Source Contribution: Released the full implementation as an open-source project to contribute to the community and facilitate reproducibility."
      ],
      "Result": [
        "Compatibility AUC improved from 93 → 95",
        "Fill-in-the-blank accuracy increased from 65% → 69%",
        "Training time per epoch reduced from 120 minutes → 20 minutes (5x faster)",
        "Built a production-friendly architecture using embedding caching and decoupled learning, enabling scalable deployment in real-world systems.",
        "The project received positive feedback from the community and is now referenced as a practical SoTA approach for outfit recommendation."
      ],
      "Repository": "https://github.com/owj0421/outfit-transformer"
    }
  }
]